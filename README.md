# RenTales_Official_HackNite  
This was our project for HackNite'24 at IIITB.
## Track and Contributors  
Track : Machine Learning  
Contributors : [Unnath Chittimalla](https://github.com/AspiringPianist), [Prakrititz Borah](https://github.com/SweetBunny123) and [Santhosh Vodnala](https://github.com/vodnalasanthosh47)  

## Problem Statement  

## Features
RenTales is a project that allows a user to generate a fully fledged visual novel by just inputting a single prompt is a story starting line or idea.  
There is a website which you can open, to see some of the visual novels fully generated by RenTales.  
Context-Aware music is played by utilizing the current scene's script predicted by the BERT model, tuned for outputting mood in a range of 1-5. (1 being negative, 3 is neutral and 5 is positive)  
Also, character images and backgrounds are generated in a similar manner by referencing the current script automatically.  
The generated visual novel can be played through Ren'Py which is something like PowerPoint but for visual novels.  
We are using automatic1111's stable diffusion model, slightly tweaked to output anime-style images.  
The model is aware of popular movies and anime series so, user can prompt without worries of the model being out of context.  
User-Friendly visual novels with dialogues, character images and background images are generated of about 5 minutes in length.  
Model utilized for getting a base story idea is Llama2:7b (sourced from Ollama, 4-bit quantized version).  
Model utilized for generating script in a human-readable format is also Llama2:7b, but a tuned version, specifically to follow the script format.  
There is a script parser that works to convert given script into a .rpy script.  
There is no need of inputting any API_TOKEN, everything runs offline.  
There is a user-friendly GUI built using pygame and tkinter, while the story is generating there is also an animated loading screen to indicate that the visual novel is under generation.  
The model runs fully offline, so there is no worry of data being collected or anonymous telemtry being done. The u

## Tech Stack
Technologies used : VSCode, Ollama, HTML, CSS, JavaScript, Python (rembg, requests, subprocess, os, pyGame, tkinter), HuggingFace (transformers, accelerate), Stable Diffusion (credits for gradio : included by automatic1111), Llama2, LangChain (for tweaking the script model), Batch Files, Nvidia CUDA, ngrok, renpy.  

## How to Run  
There is a detailed youtube video and a website explaining the system requirements and setup walkthrough in the website.  

## Deployment  
This model can be hosted on any server with atleast 6GB Ram, and have computing power equivalent or greater than a GTX1650 for optimal performance. For the time being, it can be run locally.  

## Applications  
Content creation (youtube shorts), Entertainment, Assisting in story generation, inspiration for Visual Novel Game Developers, Facilitate immersive teaching experiences, storytelling platforms.  

## Further improvements  
Dynamic character expression changes using faster image-to-image models, Text-To-Speech through pyttsx3 or models like whisper.ai to make the story more immersive.  

## Demo Videos  
links here


